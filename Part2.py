##Part 2
'''
First pass - choose 90 more spikes to make a more general sample spike
-threshold? keep paper standards?
-computation time (TBD)
'''

import os, math
os.chdir("/Volumes/KINGSTON/")

def compute_relation(x, y):
    '''(list, list) -> float
    x is the current window in the EEG data
    sample_spike is the list of values generated by Part 1 and modified by\
    Part 2
    Return sample correlation value'''
    
    x_avg = sum(x)/float(75) #N
    y_avg = sum(y)/float(75) #N
    numerator = 0
    x_denom = 0
    y_denom = 0
    for i in 75: #N
        numerator += ((x[i] - x_avg) * (y[i] - y_avg))
        x_denom += ((x[i] - x_avg) * (x[i] - x_avg))
        y_denom += ((y[i] - y_avg) * (y[i] - y_avg))
    denominator = math.sqrt(x_denom * y_denom)
    return numerator/denominator

def first_pass(filename, channel, sample_times, sample_spike):
    '''(string, string, list, list) -> list
    samepl_times is the list of 10 times (float) that were used to formulate\
    original sample spike
    Use compute_relation to modify sample_spike with 90 other qualifying spikes
    Return modified sample_spike'''
    
    f = open(filename)
    first_line = f.readline()
    time_and_channels = first_line.split("-Ref,")
    time_and_channels[-1] = time_and_channels[-1].rstrip("-Ref\n")
    for i in range(len(time_and_channels)):
        if time_and_channels[i] == channel:
            index = i
    line = f.readline()
    currtime = float((line.split(","))[0])
    
    count = len(sample_times)
    while count < 100:
        if currtime not in sample_times:
            window = []
                for n in 75: #N
                    window.append = float((line.split(","))[index])
                    line = f.readline()
            if compute_relation(window, sample_spike) > 0.97: #threshold
                for i in 75: #N
                    sample_spike[i] = ((sample_spike[i] * float(len(sample_times)))\
                    + window[i])/float(len(sample_times) + 1)
                    sample_times.append(currtime)
                count += 1
        line = f.readline()
    #what if 100 aren't found before the file ends?
    return sample_spike